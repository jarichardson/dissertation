\documentclass[12pt,letter]{article}

\usepackage{amsmath}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{booktabs}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}

\usepackage{gnuplottex}
\usepackage{subcaption}
\usepackage{caption}
\captionsetup{font={sf,small},labelfont=bf,width=0.95\textwidth}
%\usepackage{wrapfig}
\usepackage{multirow}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}

\title{Benchmark Validation and Bayesian Analysis of Lava Flow Model Performance}
%\date{}
%\author{Jacob Richardson, Laura Connor\\ Charles Connor, Sylvain Charbonnier}
\author{Jacob Richardson}

\usepackage[margin=1in]{geometry}
\usepackage{setspace}
%\doublespacing

%\usepackage{lineno}
%\linenumbers

\usepackage{titlesec}
\titleformat*{\section}{\large\bfseries} %LARGE, Large, large
\titleformat*{\subsection}{\normalsize\bfseries} %LARGE, Large, large

%Geology Papers are limited to ~5000 words

\begin{document}

\maketitle

\section*{Abstract}
	Modeling lava flows through cellular automata (CA) methods enables a computationally inexpensive means to quickly forecast lava flow paths and ultimate areal extents. A CA program has been created in the program language C that is modular, which enables a combination of governing CA rules to be evaluated against each other. My objective is to find a successful combination of automata behaviors that accurately forecasts lava inundation and behaves like a bingham fluid. To fulfill this objective, four benchmarking levels have been devised to test lava spreading algorithms against increasingly complex tests. These levels are 1) verification of the code by testing for conservation of mass; 2) testing for flow self-similarity given inconsequential variations of arbitrary surfaces; 3) testing for replication of Bingham flow morphology on simple surfaces and; 4) testing for replication of real lava flow morphologies on pre-eruptive surface models. Currently the best-fitting lava spreading algorithm for these four benchmarking tests might be an algorithm which spreads lava proportional to slope and where each automaton is able to spread lava in 8 directions.

\section{Introduction}
	Lava flows as a gravity current on the surface of the Earth when liquid magma is effused at the surface with little or no explosivity. In the vacinity of active volcanoes, lava flows represent significant long term impact to infrastructure. In the past, lava flow hazard has been mitigated with the construction of physical diversions and at least once in 252 AD by the supernatural grace of St. Agatha of Sicily who died the year prior. Modern science suggests, however, that forecasting the flow path of lava from active volcanoes might be more useful than St. Agatha for communities impacted by effusive volcanism.

	Methods of forecasting lava flows range from simple predictions using empirical relationships between magma flux and flow length \citep{Glaze2003}, to 1-D numerical solutions such as FLOWGO \citep{harris2001flowgo}, to advanced computational fluid dynamics codes like lavaSIM \citep{hidaka2005vtfs}. All modern numerical flow models by nature trade precision in simulating physical processes with computer run-time, so that while FLOWGO is relatively fast it only predicts downslope flow length, while lavaSIM solves Navier-Stokes equations to produce a 3-D flow distribution at the expense of large computational requirements.
	
	Cellular Automata (CA) methods have been developed to simulate fluid flow, including lava spreading \citep{barca1994cellular}. In contrast to CFD codes, these do not generally attempt to compute Navier-Stokes equations but instead abstract many physical parameters, such as viscosity and temperature, into more or less empirical rules. The benefit of CA methods for simulating lava flows is most noticeable in the reduced computer time necessary for simulation compared to CFD methods.
	
	Multiple CA lava flow algorithms exist, such as SCIARA \citep{crisci2004simulation}, MAGFLOW \citep{del2008simulations}, ELFM \citep{damiani2006lava}, and LavaPL \citep{connor2012}. These algorithms are variations on a theme, where the largest difference between each is how lava is distributed from one automaton to its neighbors. For instance, three versions of SCIARA allow for lava to spread in cardinal directions \citep{barca1994cellular}, in hexagonal directions \citep{crisci2008lava}, or in directions based on an inherent velocity calculated in an eulerian way for each automaton \citep{avolio2006sciara}. MAGFLOW and ELFM by contrast to the original SCIARA algorithm implements 8 directions of spreading. LavaPL and SCIARA both spread in four directions but the apportionment of lava from one automaton to neighbors is based on a different algorithm.

	While several lava flow simulators now exist, each have been made and tested with different lava flows or aspects of flows in mind. Because of this, selecting a specific algorithm to effectively model lava flow hazards can be a necessary, if unwanted challenge. To address this problem, we propose a hierarchical benchmarking scheme to objectively rank different flow spreading algorithms. This hierarchy tests simulated output against increasingly complex tests, from simply conserving mass to replicating the paths and ultimate areal extents of real lava flows. These benchmarking methods can be applied to any flow algorithm that provides at least a list or map of inundated locations over various topographies.

	In this paper, multiple lava flow algorithms are tested using a new modular lava flow code, which I have named MOLASSES (standing for \textit{MOdular LAva Simulation Software in Earth Science}). This code, implemented in C, is a Cellular Automata code which tracks a population of equal-area spaced cells over a grid, that is defined by a digital elevation model (DEM). These cells may or may not be inundated with lava and they are governed by universal rules. Because MOLASSES has been designed in a modular way, it is relatively quick to modify the flow algorithm. Using this code while changing methods of lava distribution enables code output in a constant format, which simplifies the comparison of methods.
	
	In Section \ref{sec:MOLASSES}, I will further describe how CA is applied to lava flows and detail how a CA simulation is carried out in the MOLASSES code. I will introduce a hierarchy of benchmarks in Section \ref{sec:benchmark} that can be used to verify and validate different lava flow algorithms using increasingly complex model parameters. Results from applying these benchmarks to six flow algorithms will be presented in Section \ref{sec:BMResults}. In Section \ref{sec:Bayesian} I will then expand on the final benchmark level (validation against real flows) with a Bayesian approach to improving model performance for the 2012-3 Tolbachik Lava Flow. The results from these Sections will be discussed in Section \ref{sec:discussion}.
	
	\subsection{Case Study Area: 2012-3 Tolbachik Lava Flow}
The Tolbachik lava flow began in November 2012, originally being sourced from a long fissure vent south of Tolbachik Dol. Initial magma flux was estimated to be 440~m$^3$~s$^{-1}$ \citep{belousov2015overview}. The fissure vent ultimately coalesced into two main vents, seen in TanDEM-X data and the flux dropped significantly to between 100 and 200~m$^3$~s$^{-1}$. Early stages of the flow carried lava west to a maximum runout of 14.5~km and later stages beginning in January or February, carried lava east. The total emplacement volume is $\sim$0.5~cu.~km. with 0.38~cu.~km. of that being to the west. TanDEM-X data show that the modal thickness of the flow is 7.8~m, and that the overall thickness distribution is log-normal. After the flow ceased, the total emplacement area was mapped using orthophotos and TanDEM-X data where clouds were present in the images by \citet{kubanek2015lava}.
	

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%MOLASSES%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{A Modular Cellular Automata Algorithm for lava flows}\label{sec:MOLASSES}

CA in lava flows has historically been defined as a 2-dimensional space, which is divided into equal-area grid cells, such as those found in a common digital elevation model (DEM). Within the location of each cell is defined an ``elementary automaton'' (\textit{ea}) that has a set of properties, is governed by a set of global rules, and has a set list of neighboring automata. While the behavior rules that each \textit{ea} follow is identical to those of all other automata, its behavior is only dictated by local phenomena. Specifically, the amount of lava that flows in or out of an \textit{ea} will depend on properties such as lava thickness and elevation within it and its neighbors. Because grid cells and \textit{ea} are fundamentally inseperable in this application, I will refer to \text{ea} as cells.

The set of cellular automata is defined as
	\begin{equation}
		\mathbf{A} = \mathrm{\{E^2, V, S, X, \sigma, \gamma\}}
	\end{equation}
	where E$^2$ is the set of point locations of cells in \textbf{A}, V$\subset$E$^2$ is the set of vent or source locations, S is the set of substates within each cell, and X is the local neighborhood that each cell can directly influence \citep{barca1994cellular}. $\sigma$ and $\gamma$ represent the transition functions and source functions within \textbf{A}. 
	
	Practically, E$^2$ is a set of coordinate pairs denoting row and column addresses of cells in a larger grid. S($i$,$j$), which represents the set of substates for the cell at row $i$, column $j$, includes S$_e$, the underlying elevation of an automaton; S$_h$, the thickness of lava within the cell; and S$_h0$, the critical thickness, above which lava will spread from a cell. Some algorithms include S$_T$, or the cell temperature in this set. X, in a four-connected neighborhood scheme, is given as \{(0,1), (0,-1), (1,0), (-1,0)\}, where (0,0) is the location of a cell under evaluation. $\sigma$ is the change of substates in S for each cell from timestep $t$ to $t+1$, or S$^{t}\rightarrow$S$^{t+1}$. $\gamma$ specifies the lava emitted at locations within V. The implementation of these sets within the CA structure \textbf{A} is described in detail below.
	
	\subsection{MOLASSES Algorithm Outline}
		MOLASSES is constructed with nine modules which each have a specific task, either carrying out the CA simulation, reading model input, or writing model output. The nine modules are:
		\begin{enumerate}
			\item{\textbf{DRIVER}} Calls modules in sequence to execute the flow algorithm.
			\item{\textbf{INITIALIZE}} Reads a user-provided configuration file to define model parameters.
			\item{\textbf{DEM\_LOADER}} Imports a raster file to define the elevation model.
			\item{\textbf{INITFLOW}} Uses model parameters to define data arrays.
			\item{\textbf{PULSE}} Incrementally adds lava to source locations.
			\item{\textbf{DISTRIBUTE}} Determines whether to spread and how to spread lava between cells.
			\item{\textbf{NEIGHBOR\_ID}} Identifies the cell neighborhood.
			\item{\textbf{ACTIVATE}} Adds newly inundated cells to the list of active cells.
			\item{\textbf{OUTPUT}} Writes model results to a file using user-specified formats.
		\end{enumerate}
		
		Model parameters are specified by a user through a text configuration file, which must include 1) a digital elevation model (DEM), 2) a residual lava flow thickness, 3) at least one vent location, 4) the total volume and ``pulse volume'' of this vent, and 5) an output file path. The lava flow thickness defines the CA value of S$_h0$, where cells with flow thicknesses S$h>$S$_h0$ will spread all lava to their neighboring cells, while cells with less lava will retain their lava. The ``pulse volume'' defines $\gamma$ and the amount of lava to emit at the source location at each time step. The total volume constrains $\gamma$ as lava will not be introduced to the source location after the total volume has been delivered. Modules within MOLASSES that further execute the CA simulation are detailed below.
		
	\subsection{Cells in E$^2$}
		%DEM_LOADER
		%INITFLOW
		%ACTIVATE
		Information for cells in the grid defined by E$^2$ is stored in two ways, for code efficiency. First, some information of the CA structure \textbf{A} is stored in a Global Data Grid. This grid stores information known at the beginning of the simulation, such as the user supplied residual flow thickness and the elevation. Grid dimensions are set in the \textbf{DEM\_LOADER} module to be identical to the user-specified raster DEM. This module then imports the elevation of each raster pixel into the corresponding grid cell location. After this operation, the residual flow thickness is also stored in the grid.

		The second information storage method is a list defined in the \textbf{INITFLOW} module. The ``Active List'' is declared with a length that corresponds to the theoretical maximum number of cells that can be inundated by lava. This list contains data that is updated during the simulation, including lava thicknesses, $S_h$, within cells. As cells are determined within the simulation to be inundated with lava for the first time, their row and column addresses, as well as their lava thicknesses are appended to the Active List with the module \textbf{ACTIVATE}.
		
	\subsection{Source Locations, L, and the Source Function, $\gamma$}
		%INITFLOW
		%PULSE
		Initially in the Active List, \textbf{INITFLOW} only declares source location(s) as the first few elements of the list. These source locations are flagged in the list to be identified as source locations by other modules.

		The \textbf{PULSE} module carries out the source function, $\gamma$. In this module, a separate array stores each source vent's volume parameters. The pulse volume is added to the quantity of lava in the source cell and is subtracted from the remaining volume. The remaining volume is initially set as the total volume given in the configuration file, so PULSE continues to add lava to the source locations at each time step until remaining volume is 0.
		
	\subsection{Substates, S, and the Transition Function, $\sigma$}
		%INITFLOW
		%DISTRIBUTE
		Substates which cannot change, such as the cell elevation S$_e$ and the residual flow thickness S$_h0$, are stored within the Global Data Grid. Substates which do change, primarily flow thickness, S$_h$, are stored in the Active List and are allowed to change from timestep to timestep. These values are initialized in \textbf{INITFLOW} where thicknesses are set to 0.
		
		The transition function, $\sigma$, is defined in the \textbf{DISTRIBUTE} module. Cells in this module are evaluated in order of their inundation (i.e. vents are evaluated first and distal cells are evaluated last). The incoming and outgoing quantity of lava from each cell is stored in the Active List. Generally, if a cell has a flow thicknesses S$h>$S$_h0$, it will spread the lava above S$_h0$ to any neighbors lower in elevation than itself. Transition algorithms can vary, leading to multiple DISTRIBUTE module algorithms.
		
		
		Multiple possible transition functions can effectively spread lava from and to cells in a manner that might replicate lava in real life. Selecting the best transition function is the purpose of the validation benchmarks described in Section \ref{sec:benchmark}. In this project three main variations are combined and tested which vary how slopes are treated, the neighborhood size, and if any neighbors are eliminated from the neighborhood based on their relationship to the cell.
			
		In the LavaPL algorithm given by \citet{connor2012}, lava is apportioned from one cell to its neighboring cells proportional to slope. The total relief between a cell and its lower neighboring cells is measured and each lower cell gets the amount of lava given by the central cell, S$(\alpha)_h-$~S$(\alpha)_{h0}$, multiplied by its proportional relief given by 
		\begin{equation}
			\mathrm{S}(\alpha)_h-\left(\mathrm{S}(\xi)_h\times\sum^{i=N^x}(\mathrm{S}(\alpha)_h-\mathrm{S}(i)_h\right)
		\end{equation}
		where $N^x$ is the number of lower neighbors. Another spreading strategy would be to spread lava independent of the slope, or ``slope-blind'' where all lower neighbors receive the same amount of lava.
		
		The size of the neighborhood, X, in CA algorithms is commonly 4 or 8 in cardinal or ordinal directions. Here both have been implemented, which enables the benchmarks to test whether 8 spreading directions increases the performance of these tests.

		Though the size of the neighborhood is set identically for each cell, fewer neighboring cells will actually receive lava from a central cell due to the transition function. For instance, only neighboring cells lower than the central cell receive lava, as described above. However, other neighbor elimination rules can be implemented. One has been designed by \citet{connor2012}, where the cell that initially gives lava to another cell is forever eliminated from the receiving cell's neighborhood. This is done by creating a ``parent-child'' relationship for each activated cell in \textbf{A}. Simply, child cells cannot give lava to their parent cells. This transition function rule is tested against no parentage rules in competing MOLASSES algorithms.
		
	\subsection{Cell Neighborhood, X}
		%NEIGHBOR_ID
		The final set in the CA is the cell neighborhood X and is defined by the \textbf{NEIGHBOR\_ID} module. This neighborhood is usually either 4-connected (von Neumann neighborhood) or 8-connected (Moore neighborhood). Four-connected neighborhoods are defined as the row, column coordinates \{(0,1), (0,-1), (1,0), (-1,0)\}, where (0,0) is the location of a cell under evaluation, while the set elements might correspond to North, South, East, and West. Eight-connected neighbors include the ordinal directions, Northeast, Southeast, Northwest, and Southwest: \{(0,1), (0,-1), (1,0), (-1,0), (1,1), (-1,-1), (1,-1), (-1,-1)\}.
		
		NEIGHBOR\_ID is implemented within the DISTRIBUTE module to evaluate cells within X, and determine whether they are lower in elevation (including their lava) than the central cell. If one is lower, NEIGHBOR\_ID returns their relief, or the difference in elevation between the cell and the central cell, to the DISTRIBUTE module.

			
			
			
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%HIERARCHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\section{A Benchmarking Hierarchy}\label{sec:benchmark}
	
	The strategy implemented in this paper follows the advice of \citet{bayarri2007framework} for validating computer models, namely ``1) defining the problem; 2) establishing evaluation criteria; 3) designing experiments; 4) approximating computer model output; 5) analyzing the combination of field and computer run data.'' The sixth step in their validation process, feeding results back to revise models, has been done informally in determining how to alter spreading algorithms in future benchmarking attempts. Each level below presents a problem for a lava spreading algorithm to complete. These fundamental problems (e.g. replicating a Bingham flow) are evaluated using simple tests that demonstrate the problem. The relevant model output for each of these tests is a list of locations that have been inundated by lava. Planned future tests will also require the thickness of lava at each location inundated by lava in a given test. Lastly, tests compare model output with expected output. After verification (Level 0), the first validation level tests model results with other model results; the second tests model output against expected analytical solutions; and the third level tests model output from field data.

	\subsection{Level 0: Conservation of Mass}
		\subsubsection{Conservation of Mass}\label{test:CoM}
			Before the results of a lava flow simulation can be benchmarked or validated, it must be verified to at least prove that conservation of mass is preserved. A lava flow simulation will therefore not be tested against the following benchmark tests until this conservation of mass requirement is shown to be fulfilled. By the design of MOLASSES, this test is performed for each simulation by summing the total volume delivered to vents, as specified by the user in a configuration file, and comparing it to the sum of volume in all cells at the end of the simulation. If the quantities are not equal, the test fails, mass is not conserved, and the code is not able to be validated.
	
			\begin{center}
				\begin{tabular}{l}
					\toprule
					\textbf{Test \ref{test:CoM} Algorithm}\\
					\midrule
					Implemented in MOLASSES:\\
					1.~$V_{in}\leftarrow \displaystyle\sum^{Vents} V_{v}$, for each vent, $v$.\\
					2.~$V_{out}\leftarrow \displaystyle\sum^N V_{c}$, for each cell, $c$.\\
					3.~Test $V_{in}-V_{out}=0$\\
					~\tabitem \textit{True}: Success\\
					~\tabitem \textit{False}: Failure\\
					\bottomrule
				\end{tabular}
			\end{center}

	\subsection{Level 1: Self similarity given ersatz parameter space variation}
		The first level of model validation tests that a lava spreading algorithm remains the same given dummy, or ersatz, changes in parameter space. To evaluate the performance of algorithms at this level, parameters such as elevation values of the underlying surface model are changed in a way that should not effect model output. Model output is then compared with model output from effectively identical parameters to see if model output is also effectively identical. For instance, a slope to the west and an identically dipping slope to the east should produce lava flows of equal length and shape, all other flow parameters remaining equal. Because the larger goal of this level is simply to test the ability for algorithms to remain unchanged and they are not yet expected to be realistic flows, parameter space can be arbitrarily assigned initially.
		
		\subsubsection{Rotating Sloped DEM}
			Miyamoto and Sasaki (1997) performed a simple validation test on two CA-like flow simulators (Ishihara, 1990 and Miyamoto and Sasaki, 1997) where a sloped DEM was rotated 45 degrees from ``south'' to ``southeast''. This test was performed to verify that the flow models had the same run-out regardless of the arbitrary slope direction. The DEM rotation scheme by Miyamoto and Sasaki (1997) is adopted and expanded, so that a DEM with a simple sloping face is rotated 180 times at an increment of 2$^{\circ}$. The farthest point of a simulated flow from a given model is reported for each slope direction. A perfect flow model will have no variation in distance traveled with respect to slope direction.

			\begin{center}
				\begin{tabular}{l}
					\toprule
					\textbf{Rotating Slope Test Algorithm}\\
					\midrule
					1.~Assing constant DEM and Flow parameters\\
						~\tabitem $\phi:=$DEM slope\\
					2.~Write configuration file\\
					3.~For 180 azimuths, $\theta$, from 0-360$^{\circ}$\\
						~\tabitem create DEM dipping $\phi$, $\theta$ from N.\\
						~\tabitem run \textbf{MOLASSES} over DEM\\
						~\tabitem $l$:=i,max dist$\{C_0-C_i\}$\\
						~\tabitem $d_{l,\theta}$:=dist$\{C_0-C_l\}$\\
						~\tabitem $w$:=i,max dist$\{\overrightarrow{C_0C_l}-C_i\}$\\
						~\tabitem $d_{w,\theta}$:=dist$\{\overrightarrow{C_0C_l}-C_w\}$\\
					4.~Find average, $\mu$, standard deviation, $\sigma$ of $d_l$,$d_w$\\
						~\tabitem CV$_l$:= $\sigma_l/\mu_l$\\
						~\tabitem CV$_w$:= $\sigma_w/\mu_w$\\
					5.~Define success, failure based on CV.\\
					\bottomrule
				\end{tabular}
			\end{center}


		\subsubsection{Potential Level 1 Tests}
		\paragraph{Scaling Spatial Resolution}
			A second DEM-altering test would be where lava flows will be simulated over surfaces of different spatial resolutions. These surfaces could either be flat or a slope. The largest inhibitor of this test currently is a parameter in MOLASSES known as the Pulse Volume. At differing spatial resolutions, the choice of Pulse Volume changes the flow runout length in a way that is not necessarily proportional to resolution, so it is not yet known how to choose this parameter for this test.

	\subsection{Level 2: Replication of flow morphologies on simple physical surfaces}
	
	The second benchmarking level is the first step in validating lava flow algorithms against realistic flow expectations. Instead of parameter space being arbitrarily defined, which was the case in Level 1, the defined parameter space informs tests at this level as to what the model output should be.
	
		\subsubsection{Flow areal extent approximates a circle on a flat plane}\label{test:Bing_circ}
		
			As lava flows on a large scale are well described as Bingham fluids, a flow simulation can be further tested by being compared to analytical solutions or experimental observations of these fluids under simple conditions. For instance, a lava flow on a perfectly flat surface might be expected to create a circular areal extent. Another example is that lava flows are expected to thicken up-slope when encountering a vertical obstacle.
	
			Here we measure flow algorithm performance on a flat surface from a single vent source location. Two tests measure this performance. First, it is expected that the flow will be circular. To measure the extent to which the simulated flow replicates a circle, we measure the inundated area and compare that to the area of a circle which circumscribes the flow exactly. This can be described as
			\begin{equation}
				Fit = \frac{A_{flow}}{\pi d_{max}^2}
			\end{equation}
			where $d_{max}$ is the farthest extent of the simulated flow from the vent. A perfect match to a circle would result in a $Fit=1$. With the same maximum distance from the vent (i.e. the distance from the center to a vertex) a perfect square would cover 64\% of the area of a circle, ergo $Fit=0.64$. An octagon would have a fit of 0.90. We consider a model to successfully pass this test if it produces a flow of $Fit>0.90$, or if the flow approximates a circle better than an octagon. The model fails this test if if produces a flow of $Fit<0.64$, where a square better describes a circle than a flow generated from the model.

			\begin{center}
				\begin{tabular}{l}
					\toprule
					\textbf{Test \ref{test:Bing_circ} Algorithm}\\
					\midrule
					1.~Create flat DEM with spatial resolution, $R$\\
					2.~Write configuration file for flow\\
					3.~Run \textbf{MOLASSES} over DEM\\
					4.~Define results:\\
						~\tabitem $d_{max}$~:=~max dist$\{\overrightarrow{C_0C_l}-C_i\}$\\
						~\tabitem $N$~:=~Number of cells, $C$, inundated\\
					5.~Compare $N$ with $N_{circle}$,$N_{octagon}$,$N_{square}$ where:\\
						~\tabitem $N_{circle}:=\pi d_{max}^2/R$\\
						~\tabitem $N_{octagon}:=2.82842 d_{max}^2/R$\\
						~\tabitem $N_{square}:=2d_{max}^2/R$\\
						~1. If $N>N_{octagon}$: Success\\
						~1. If $N<N_{square}$: Failure\\
					\bottomrule
				\end{tabular}
			\end{center}


		\subsubsection{Potential Level 2 Tests}
			\paragraph{Flow thickness profile approximates a Bingham fluid on a flat plane}
				A second flat-surface test compares the averaged flow thickness profile away from the vent from a theoretical axisymmetric thickness profile of a viscoplastic fluid. The analytical solution for height with respect to radius is given by Griffiths (2000) as
				\begin{equation}
					h(r)^2 = \frac{2\sigma_0(R-r)}{\rho g}
				\end{equation}
				where $\sigma_0$ is the yield strength of the flow, R is the outer radius, and $\rho$ is the fluid density. As $\sigma_0$ and $\rho$ are not generally given \textit{a priori} in CA codes, we will use $C$ where $C=\sigma_0/\rho$ as a placeholder. For each model, a flow will be generated on a flat plane, a $\chi^2$ test will be used to find the best fit $C$, which will have the least error between the analytical and the simulated axisymmetric thickness profiles, and the misfit will be reported.

			\paragraph{Flow morphology approximates a Bingham fluid on a slope}
				Another Level 2 test tests algorithms' abilities to recreate viscoplastic flow morphology for a flow on a slope. Following Osmond and Griffiths (2001), the areal footprint of a yield strength fluid can be solved by comparing its strength, total volume, and the underlying surface slope. Because it might be hard to scale the model to findings from Osmond and Griffiths \textit{a priori}, the best fitting Bingham parameters can be found for a given model output and the error from this best fit can be compared to the error from the output of other flow algorithms. This would likely also inform how flow spreading algorithms scale to real world dimensions.

			\paragraph{Thickness profile approximates a Bingham fluid behind an obstacle}
				Bingham fluids flowing over a significant obstacle on a slope exhibit a bow shock upslope from the obstacle. Using an obstacle such as a cylinder or a triangle, the thickness profile along the flow axis upslope of the obstacle as determined by a numerical solution can be compared with model output from a flow algorithm.



	\subsection{Level 3: Replication of real lava flows over complex topography}
		The recent availability of global or near-global topographic datasets, such as SRTM or ASTER GDEM has enabled the direct observation of the underlying surface of even more recent lava flows. The extents of lava flows such as the 2012-3 Tolbachik lava flow, in conjunction with available pre-eruption DEMs, is the final benchmarking test for lava flow algorithms. At this level, model inputs must reflect reality, which naturally makes parameter spaces used in applicable tests more complex than those used in previous levels. Ultimately, if a lava spreading algorithm succeeds at this level after performing well in previous levels, the algorithm is considered validated against field data.

		\subsubsection{2012-3 Tolbachik, Russia lava flows}\label{test:Real_Tolbachik}
			The goodness of fit between a simulated flow and a mapped lava flow can be simply measured by the Jaccard coefficient. This parameter is the ratio of the intersection area inundated by both the simulation and the real flows by the union area inundated by either. To illustrate, this test has been performed recently by Kubanek et al. (submitted) for the 2012-3 Tolbachik flow where a MOLASSES model configuration, explained later, produced a lava flow with a 59\% fit to the mapped flow. This result means that 59\% of the area inundated by either the simulated flow or the mapped flow, the union, was inundated by both the simulated and the mapped flows. Conversely, 41\% of the area was either modeled to have been inundated but wasn't or was modeled to be lava-free but actually was inundated by lava. These are generally known as false positives or false negatives, respectively.
			

			%Go on about how the Jaccard DEM is constructed maybe? or maybe this is results material.
			\begin{center}
				\begin{tabular}{l}
					\toprule
					\textbf{Test \ref{test:Real_Tolbachik} Algorithm}\\
					\midrule
					1.~$C_{real}$~:=~Locations of grid cells in Tolbachik DEM inundated by 2012-3 Flow.\\
					2.~Run \textbf{MOLASSES} over Tolbachik DEM\\
					3.~Define results:\\
						~\tabitem $C_{model}$~:=~Locations of cells, $C_i,...,C_N$, inundated by \textbf{MOLASSES} flow.\\
					4.~$Fit:=\cap_C/\cup_C$\\
						~\tabitem If $Fit\ge0.5$: Success\\
						~\tabitem If $Fit<0.5$: Failure\\
					\bottomrule
				\end{tabular}
			\end{center}
			
		\subsubsection{Potential Level 3 Tests}
		\paragraph{Glass Pours}
			A potentially simple test for Level 3 that bridges Level 2 with 3 would use glass pour experiments over simple topography in real life. The experimental data would be collected using measurements taken from the USF magma lab where molten glass is poured over sand surfaces. The surfaces created would be simplifications of real lava flows, similar to the perfectly simple surfaces used in Level 2, but would use real life data instead of numerical solutions to perfectly Bingham fluid motion. Flow morphology of glass pours could be measured after flows have cooled or through new photogrammetric approaches called Structure from Motion.
			
		\paragraph{Nornahraun, Iceland and other real lava flows}
			Validating a lava flow algorithm against just one real life example of a lava flow does not necessarily give confidence that the flow algorithm will perform well for all lava flows. To test the robustness of the model for multiple types of lava flows, it would be beneficial to validate the model against other lava flows like the Pahoa flow in Hawaii, or the new Nornahraun flow in Iceland.
			
		

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%RESULTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}\label{sec:BMResults}
	
	In order to be considered for benchmark validation, all algorithms had to conserve mass, so the verification level 0 will not be further discussed here. For the following tests, algorithms are described using the components discussed in Section \ref{mod:DISTRIBUTE}. The three letter codes thus describe whether the spreading algorithm uses 1) 4 or 8 neighbors, 2) Parent-child relationships or not, and 3) Slope-proportional or Equal spreading. For the algorithm used by LavaPL in \citet{connor2012}, the code would therefore be 4/P/S.

	\subsection{Level 1: Self-similarity}
	To perform the self-similarity test given a rotating surface model, a simple slope was created, dipping 18$^{\circ}$. DEMs with a spatial resolution of 1~m and a height and width of 750~m were created for this surface with slope azimuths at 5$^{\circ}$ increments from 0-90$^{\circ}$. Eight different transition functions were run over this slope, with a source vent at the DEM centroid which erupted 1000 cubic meters. Pulse volume was 1~cubic~meter and the residual thickness was 1~m.
	
	\begin{figure}[h!]
		\centering
		\includegraphics[width=\linewidth]{figures/lava_C_4N_slope}
		\caption{\textit{Rotating slope test for a 4-connected flow algorithm with parent-child relationships which spreads lava proportional to slope (4/P/S). Slope dip is 18$^{\circ}$, dipping 0N, 30N, and 80N from left to right. The flow length and aspect ratio are similar and the flow direction is in the slope direction, so even though the flow is oddly shaped, it passes Level 1 criteria.}}
		\label{fig:slope}
	\end{figure}
	
	Flow runout lengths were calculated by finding the distance between the vent location and the farthest location recorded in the ASCII flow output file. For the eight different transition functions tested, runout length varied between 60-160~m. Flow widths were calculated by finding the farthest point away from a line between the farthest flow point and the vent location on either side. Aspect ratio is calculated as the ratio between runout length and flow width. Direction error is calculated as the degree difference between the slope direction and the direction of the farthest flow point from the vent.
	
	For each flow algorithm, these statistics were calculated 18 times, for each DEM created. Variance for length and aspect ratio were calculated as the ratio of their standard deviations to their means. For instance, if mean runout length for the 18 flows is 100~m and the standard deviation of the 18 lengths is 2~m, the runout length variance is 2\%. The mean direction error is also calculated for the set of flows from each algorithm. These are reported in the table below.

		\begin{center}
			\textbf{DEM Rotation Results}
			\begin{tabular}{l c c c}
				\toprule
				Transition&Run-out&Aspect Ratio&Mean Direction\\
				Function&Variance&Variance&Error\\
				\midrule
				4/P/S &2.7\%&6.7\%&1.2$^{\circ}$\\
				8/P/S &4.4&12.2&0.9\\
				4/N/S &9.6&19.7&1.3\\
				8/N/S &3.9&7.5&0.6\\
				4/P/E &21.6&38.6&14.2\\
				8/P/E &7.2&13.8&5.4\\
				4/N/E &21.6&38.7&14.1\\
				8/N/E &7.2&13.8&5.5\\
				
				\bottomrule
			\end{tabular}
		\end{center}
		
		While with an ideal spreading algorithm, variances and direction error would be 0 under a rotating slope, all spreading algorithms tested performed differently as DEM direction changed. Deciding which pass or fail this test is not necessarily clear from the above results. However, some algorithms can be discarded from their high mean direction error; algorithms with mean direction errors larger than 2$^{\circ}$ can be visually seen, when the flow is mapped, to have a systematic flow direction. This independence from the slope direction suggests that the dummy direction parameter changes the performance of these flows. The flow algorithm with the least flow length variance was the 4-connected, parent-child, slope-proportional strategy implemented in LavaPL.

	\subsection{Level 2: Bingham Flow Approximation}
		
		A flat surface DEM is created with a spatial resolution of 1~m and a height and width of 1300~m to run flows from the centroid. These flows should replicate a circle, which is judged by comparing the number of inundated locations given in the ASCII model output with the number of locations in the DEM within a circle circumscribing the lava flow. A result of 1.0 indicates the flow performs as well as a circle, a result of 0.90 indicates that the flow replicates a circle as well as an octagon, and a result of 0.64 indicates that the flow replicates a circle as well as a square.
		
		\begin{figure}[!h]
		\centering
		\includegraphics[width=0.7\linewidth]{figures/pancake}
		\caption{\textit{Two flat surface tests for slope proportional spreading algorithms with parent rules. On the left the flow is 4-connected (4/P/S), while on the right the flow is 8-connected (8/P/S).}}
		\label{fig:pancake}
	\end{figure}
	
		
		\begin{center}
			\textbf{Bingham Circle Results}\\
			\begin{tabular}{l c c c}
				\toprule
				Transition Function&Circularity\\
				\midrule
				4/P/S & 0.55\\
				8/P/S & 0.95\\
				4/N/S & 0.55\\
				8/N/S & 0.98\\
				4/P/E & 0.77\\
				4/N/E & 1.00\\
				8/N/E & 0.99\\
				
				\bottomrule
			\end{tabular}
		\end{center}
		
		All but three flow algorithms tested above unambiguously passed the test of performing better than an octagon. Two algorithms unambiguously failed, one of which is the LavaPL algorithm that outperfomed other models in the previous test. In this test 8-connected algorithms outperformed 4-connected algorithms.

	\subsection{Level 3: Replicating Real Flows}
	
	Each transition function was tested over SRTM topography and a TanDEM-X DEM using values gathered from TanDEM-X analysis. Two vents were situated over the topography at UTM coordinates of the two active vents created in the 2012-3 Tolbachik eruption. The total combined volume output from these two vents were 0.38~cubic~km. The residual thickness of the flow is 7.8~m and the pulse volumes were defined as the product of the thickness and the spatial resolution of the underlying DEM. The Jaccard fit for each flow algorithm is listed below for both DEMs.
		\begin{figure}[!h]
			\centering
			\includegraphics[width=0.7\linewidth]{figures/tolbachik}
			\caption{\textit{Two models run over two DEMs (SRTM, top; TanDEM-X, bottom) in the Tolbachik area. Left: An 8-connected, slope-proportional, no parent algorithm (8/N/S). Right: A 4-connected, equal spreading, no parent algorithm (4/N/E). Most spreading algorithms that had appropriate runout lengths in the SRTM test simulated very long flows over the TanDEM-X DEM. The mapped flow is plotted in black.}}
			\label{fig:tolbachik}
		\end{figure}
		
		\newpage
		\begin{center}
			\textbf{Tolbachik Flow Results}\\
			\begin{tabular}{l c c c}
				\toprule
				Transition Function&SRTM DEM Fit&TanDEM-X DEM Fit\\
				\midrule
				4/P/S & 57.7\%& 53.0\%\\
				8/P/S & 61.1  & 46.8\\
				4/N/S & 57.2  & 44.0\\
				8/N/S & 61.6  & 48.3\\
				4/P/E & 51.2  & 54.2\\
				4/N/E & 54.5  & 55.7\\
				8/N/E & 59.6  & 56.3\\
				
				\bottomrule
			\end{tabular}
		\end{center}

		If success and failure are defined by having a fits of greater or less than 50\%, all models tested would pass for the SRTM DEM and about half would pass for the TanDEM-X DEM. All but one model performed worse on the TanDEM-X DEM.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%BAYESIAN APPROACH
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bayesian Applications to the Tolbachik Flow}\label{sec:Bayesian}
	Bayesian statistics are a primary tool by which scientists can update their belief in a certain phenomenon given new information, such as model output. Simple examples of this are often medical in nature. For instance, if a woman's female relatives have had breast cancer in their lives, she has a certain probability (i.e.~$P$(Cancer)) of having breast cancer herself. If a reliable medical test is administered and gives a positive result for breast cancer, the patient will rationally increase her belief in potentially having breast cancer, above the probability, $P$(Cancer) she assumed prior to the test. This belief updating occurs as long as the test is reliable, even if the test is not perfect. Likewise, if the test gave a negative result for cancer, she would rationally decrease her belief in having breast cancer, below $P$(Cancer).

	In hazard analysis, this tool can be similarly used to test the reliability of lava flow models. Toward this, I examine the different ways that Bayesian analysis can test the capability of related lava flow spreading algorithms in forecasting the areal extent of the 2012-3 Tolbachik lava flow in Kamchakta Russia. First, I will give an outline of this eruption in Section \ref{sec:tolb_back} and a basic background on Bayesian statistics in Section \ref{sec:bayes_back}. Then I will test results from the MOLASSES lava flow model with varying ``Pulse Volume'' parameters using Bayesian statistics in Section \ref{sec:lava_app}. I will further explore the applications of Bayesian statistics when dealing with model uncertainty in a Monte Carlo fashion in Section \ref{sec:lava_MC}. The following Discussion Section will look at a way to use multiple metrics to identify an optimal model, defined as a model that most reduces unexpected economic loss, and will describe best practices to avoid artificially improving model fit statistics.

	\subsection{Bayes Theorem Background}\label{sec:bayes_back}
		Bayes theorem holds that, given events $A$ and $B$ (where $A$ might be a phenomenon and $B$ might be a test result), the conditional probability of $A$ given $B$ can be described as
		\begin{equation}
		P(A|B)=\frac{P(B|A)P(A)}{P(B)}\label{eq_bayes}
		\end{equation}
		In this equation:
		\begin{itemize}
			\item $P(A)$ is the \textit{prior}, the general probability of the $A$ occuring.
			\item $P(B)$ is the general probability of $B$ occuring. If $B$ is a test result, this might be referred to as model information.
			\item $P(B|A)$ is the conditional probability of the occurence of $B$ given the occurence of $A$.
			\item $P(A|B)$ is the \textit{posterior} probability of $A$ occurring given the occurence of $B$.
		\end{itemize}

		Three related statistical measures of model fit to a phenomenon are model sensitivity, specificity, and the Jaccard similarity coefficient. \textit{Model sensitivity} is defined as the percent of the total population within $A$ that the test $B$ correctly characterizes or models, or
		\begin{equation}
		\mathrm{Sensitivity} = \frac{|A\cap B|}{|A|}\label{eq_sensitivity}
		\end{equation}
		\textit{Model specificity} on the other hand is defined as the percent of the total population where $A$ does not occur that the lack of event $B$ correctly characterizes, or 
		\begin{equation}
		\mathrm{Specificity} = \frac{|\neg A\cap \neg B|}{|\neg A|}
		\end{equation}
		The \textit{Jaccard similarity coefficient}, or Jaccard Index, is defined as the ratio of the intersecting population of $A$ and $B$ to the union of the two populations, or
		\begin{equation}
		\mathrm{Jaccard~Index} = \frac{|A\cap B|}{|A\cup B|}
		\end{equation}

		Consider that $A$ is a natural phenomenon occuring within a population $N$ and $B$ is a test to predict $A$ for elements within the population $N$. 
		\begin{itemize}
		\item \textit{True positives} exist where $A$ occurs in elements and $B$ correctly predicts $A$. This can also be phrased as the intersection of $A$ and $B$, or $A\cap B$.
		\item \textit{True negatives} exist where $A$ does not occur and $B$ correctly predicts the absence of $A$. This can be expressed as $\neg A\cap\neg B$.
		\item \textit{False positives} exist where $A$ does not occur but $B$ incorrectly predicts $A$. This is $\neg A\cap B$.
		\item \textit{False negatives} exist where $A$ does occur but $B$ incorrectly predicts the absence of $A$. This is $A\cap\neg B$.
		\end{itemize}

		A Bayesian treatment can use the results from $B$ to update belief of $A$, using Equation \ref{eq_bayes}. The prior probability of $A$, $P(A)$, within population $N$ is given as
		\begin{equation}
		P(A)=\frac{|A|}{|N|}.\label{eq_PA}
		\end{equation}
		The model information $P(B)$ is the percent of the population where $B$ predicts $A$ (whether correctly or not), or 
		\begin{equation}
		P(B)=\frac{|B|}{|N|}.\label{eq_PB}
		\end{equation}
		The conditional probability $P(B|A)$ is the probability of $B$ predicting $A$, given $A$. This is the percentage of true positives within the population of $A$ and is equivalent to model sensitivity.

		The posterior probability of $A$ given the positive outcome of $B$, or $P(A|B)$ can then be calculated by substituting terms in Equation \ref{eq_bayes} with Equations \ref{eq_sensitivity}, \ref{eq_PA}, and \ref{eq_PB}:
		\begin{align}
		P(A|B)&=\frac{\frac{|A\cap B|}{|A|}\frac{|A|}{|N|}}{\frac{|B|}{|N|}}~\mathrm{,~or~simplified,}\label{eq_unsimplepost}\\
		&=\frac{|A\cap B|}{|B|}.\label{eq_simplepost}
		\end{align}
		$P(A|B)$ can therefore be thought of as the percentage of true positives within the subpopulation characterized by $B$. This posterior probability is not dependent on the size of the population $N$, nor does it quantify false negatives (where $A$ occurs even though $B$ does not predict $A$) in any way.

	\subsection{Improving Model Performance}\label{sec:lava_app}
		A primary way that hazard forecasting models have been validated in the past has been asking the question ``What percentage of the hazard phenomenon did the model correctly forecast?'' This is essentially asking for the model sensitivity. A person at risk of loss due to the hazard might instead want to know ``If the model forecasts loss for me, what is the likelihood that loss will actually occur?'' This is the posterior probability, $P(A|B)$ discussed above.

		Applied to lava flows and lava flow models, the population $N$ can be considered to be locations that might possibly be inundated with lava, given an eruption. The phenomenon $A$, in this case eventual inundation by lava, occurs or does not occur for each location and $P(A)$ is the probability of inundation within $N$. The test $B$ for each element in $N$ is an algorithm which models lava inundation and $P(B)$ is the probability of the flow simulation forecasting inundation within $N$. Equation \ref{eq_bayes} can be altered to:
		\begin{equation}
		P(Lava|Sim)=\frac{P(Sim|Lava)P(Lava)}{P(Sim)}\label{eq_lavabayes}
		\end{equation}
		where $Lava$ is the real phenomenon of lava inundation and $Sim$ is the model prediction of inundation, at any given location within the assigned hazard area of interest.

		Analysis performed on the 2012-3 Tolbachik flow presents an opportunity to validate lava flow models in a Bayesian framework: pre-eruptive DEMs exist at multiple spatial resolutions (e.g.~75~m SRTM and 15~m TanDEM-X), the locations of flow inundation have been mapped, and flow parameters have been estimated or measured (e.g. magma flux at the source vents, locations of source vents, flow thickness, flow volume). Lava flow models can be run using the flow parameters and pre-eruptive DEMs as input parameters, giving the subpopulation $Sim$. The mapped lava flow provides the subpopulation $Lava$. Comparing $Sim$ for different algorithms directly with $Lava$ can then quantify the valditiy of flow algorithms in a Bayesian sense.

		\paragraph{Model Execution} To populate $Sim$, I have run the MOLASSES lava flow code using TanDEM-X derived parameters, listed below:
		\begin{center}
			\textbf{MOLASSES Flow Parameters}\\
			\begin{tabular}{l l}
				\toprule
				Elevation Model & 15-m bistatic TanDEM-X, 11 Nov 2015\\
				Modal Thickness & 7.8~m\\
				Pulse Volumes & 16 equally separated volumes, [1755,14917] m$^3$\\
				\midrule
				Vent$_N$ Easting & 582800~m (UTM Zone 57)\\
				Vent$_N$ Northing & 6182100~m\\
				Vent$_N$ Total Volume & 4.63$\cdot10^7$~m$^3$\\
				\midrule
				Vent$_S$ Easting & 582475~m\\
				Vent$_S$ Northing & 6180700~m\\
				Vent$_S$ Total Volume & 1.737$\cdot10^8$~m$^3$\\
				\bottomrule
			\end{tabular}
		\end{center}
		All variables are fixed except the ``Pulse Volume'' parameter, which is the amount of lava delivered to source cells in the Cellular Automata grid of MOLASSES.

		The MOLASSES algorithm used is also fixed. The algorithm spreads lava proportional to the local slope on each side of the automaton in question, but does not have parent-child relationship laws. It is 8-connected, meaning each automaton with lava may spread lava in any or all of 8 directions in a grid around it. The chosen output of MOLASSES is an x,y,z ASCII list where x and y are easting and northing in UTM and z is the flow thickness.

		Model output is compared to a list of x,y locations in the Tolbachik area that have been inundated or not. This location list is stored in a raster with the same projection and extent as the elevation model used in MOLASSES. ASCII locations output by MOLASSES are also listed in the same projection within the same extent as the elevation model. This enables direct comparison between the Model information (i.e. $Sim$) and the mapped lava flow (i.e. $Lava$). True Positives, False Positives, and False Negatives are reported as cell counts (number of grid locations where $Lava$ and $Sim$ agree or not). Three examples of these simulations are mapped in Figure \ref{fig:pulse_map}.

		\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{figures/3flows_h}
		\caption{MOLASSES Simulations of the 2012-3 Tolbachik Lava Flows. Vents are shown as blue triangles and the mapped flow is outlined in black. a) Pulse Volume = 1755 m$^3$, the simulation far exceeds the true runout distance; b) Pulse Volume = 4387 m$^3$, this simulation performs best under the negative posterior $P(\neg Lava|\neg Sim)$ test; c) Pulse Volume = 14040 m$^3$, this simulation performs best under the posterior $P(Lava|Sim)$ test, but does not have a runout length similar to the mapped flow.}
		\label{fig:pulse_map}
		\end{figure}



		\subsubsection{$P(Sim|Lava)$ (model sensitivity): Lava destroyed my home, but did the simulation predict it?}

		Model sensitivity is the percentage of the true phenomenon $Lava$ that the test $Sim$ accurately predicted. A model sensitivity of 0\% would indicate that between $Lava$ and $Sim$ there were no true positives. Mathematically, the size of the union, $|Lava\cap Sim|$ is 0. A model sensitivity of 100\% would indicate that $|Lava\cap Sim|$ is the same size as $Lava$, or $|Lava\cap Sim|=|Lava|$. If model sensitivity is perfect, there are no false negatives, though there might be false positives.
		\begin{figure}[h!]
			\centering
			\begin{gnuplot}[terminal=latex, terminaloptions=rotate]
				unset key
				set size 0.7, 0.7
				set format xy "$%g$"
				set xlabel "Pulse Volume" rotate by 90
				set ylabel "Sensitivity"
				set ytics 0.05
				set xtics 4000
				plot "results_bayes.dat" using 1:2 with linespoints lt 4 pt 7
			\end{gnuplot}
			\caption{Model Sensitivity for MOLASSES flows with differing Pulse Volumes.}
			\label{fig_sensitivity}
		\end{figure}

		\subsubsection{$P(Lava|Sim)$: If the simulation predicts lava inundation for a given location, what is the actual chance of lava inundation at the location?}

		The posterior statistical measure is the fundamental tool of Bayesian statistics, and quantifying it enables an update of belief in risk of lava inundation. A perfect posterior value would mean that if the model simulates lava inundating a location, lava will certainly inundate that location. The posterior is calculated for simulated lava flows of different Pulse Volumes and is graphed in Figure \ref{fig_lavaGsim}. From this, it can be seen that the highest pulse volumes, which coincidentally form the shortest flow simulations, perform best with this test, with the best fit having a pulse volume of 14040~m$^3$ per algorithm loop (Figure \ref{fig:pulse_map},c). A local maximum does exist in the low pulse volumes at 4387~m$^3$ per loop.


		\begin{figure}[h!]
			\centering
			\begin{gnuplot}[terminal=latex, terminaloptions=rotate]
				unset key
				set size 0.7,0.7
				set format xy "$%g$"
				set xlabel "Pulse Volume" rotate by 90
				set ylabel "$P(Lava|Sim)$"
				set ytics 0.05
				set xtics 4000
				plot "results_bayes.dat" using 1:3 with linespoints lt 4 pt 7
			\end{gnuplot}
			\caption{Posterior $P(Lava|Sim)$ for MOLASSES flows with differing Pulse Volumes.}
			\label{fig_lavaGsim}
		\end{figure}

		%Talk specifically about the math
		%Provide examples as figures.

		\paragraph{Hazard Response Implications} The higher $P(Lava|Sim)$ is for a lava spreading algorithm, the higher certainty there is that if the simulation predicts inundation, inundation will occur. Algorithms known to have high $P(Lava|Sim)$ values should influence more people to evacuate an area, if the area is predicted by those algorithms to be hit by lava. If $P(Lava|Sim)$ is low, then it is more likely that evacuating all locations simulated to be affected would be a waste of resources.

		\subsubsection{$P(\neg Lava|\neg Sim)$: If the simulation predicts my safety, how safe am I really?}\label{sec_negpost}

		The weakness of the posterior statistic explored so far ($P(Lava|Sim)$), is that it does not measure fit of the negative results of the simulation. If the simulation does not inundate a location, this posterior does not enable the ``belief of safety,'' $P(\neg Lava)$, to be updated. Therefore I propose to use a second posterior, which I will call the \textit{negative posterior}.

		The negative posterior $P(\neg Lava|\neg Sim)$, or the probability of safety given simulated safety, is essentially the percentage of non-inundated area in the simulation that is also not inundated in real life. This can be found by defining this posterior using Bayes' Theorem similar to Equation \ref{eq_lavabayes}:
		\begin{equation}
		P(\neg Lava|\neg Sim)=\frac{P(\neg Sim|\neg Lava)P(\neg Lava)}{P(\neg Sim)}
		\end{equation}
		A perfect negative posterior would indicate that, if a model does not simulate a hit for a location, lava will certainly not inundate that location. While the posterior $P(Lava|Sim)$ is essentially population size blind, and does not rely on the number of true negatives (Equations \ref{eq_unsimplepost} and \ref{eq_simplepost}), this posterior does rely on true negatives. Thus, the size of the population, here referred to as the Potential Hazard Area, must be estimated \textit{a priori}.

		\paragraph{Potential Hazard Area} The hazard area for the 2012-3 Tolbachik Lava Flows are simply assumed to be any location below the vent elevation plus modal flow thickness (7.8~m), within a given radius. The hazard radius is calculated from the equation given by \citet{kilburn2000lava} to predict the theoretical maximum distance, $R_{max}$ of a lava flow
		\begin{equation}
		R_{max}=\sqrt{\frac{3\epsilon SQ}{\rho g\kappa}}
		\end{equation}
		where $\epsilon$ is an empirical value related to the amount of extension of lava crust allowed before it fails (10$^{-3}$), $S$ is the tensile strength of this crust (10$^7$~Pa), $\rho$ is the lava crust density (2200~kg~m$^{-3}$), $g$ is gravitational acceleration, $\kappa$ is the bulk thermal diffusivity ($4\times 10^{-7}$~m$^{2}$~s$^{-1}$) and $Q$ is the mean volumetric flow rate from the vent. From this, the hazard radius for Tolbachik is calculated to be 39 km given a magma flux of 440~m$^3$~s from the vent as was estimated early in the eruption \citep{belousov2015overview}. The total area within this radius that is also below the vent-plus-modal-flow-thickness elevation is 1,415~km$^2$. Note that the mapped flow area of 26~km$^2$ only covers 1.9\% of this defined hazard area.

		\paragraph{Results}


		\begin{figure}[h!]
			\centering
			\begin{gnuplot}[terminal=latex, terminaloptions=rotate]
				unset key
				set size 0.7,0.7
				set format xy "$%g$"
				set xlabel "Pulse Volume" rotate by 90
				set ylabel "$P($not $Lava|$not $Sim)$"
				set ytics 0.001
				set xtics 4000
				plot "results_bayes.dat" using 1:4 with linespoints lt 4 pt 7
			\end{gnuplot}
			\caption{Negative posterior $P(\neg Lava|\neg Sim)$ for MOLASSES flows with differing Pulse Volumes.}
			\label{fig_neglavaGsim}
		\end{figure}

		The negative posteriors of simulations with different pulse values are shown in Figure \ref{fig_neglavaGsim}. Unlike the previous posterior analyzed, the best performing flows have smaller pulse volumes and the best performing volume is 4387~m$^3$ per model pulse loop (Figure \ref{fig:pulse_map},b). These results, however, show very high performance for all models, where $>$99.2\% of the area not hit by the lava flow in the potential hazard area is also not hit in all simulations. This is due to the enormous relative size of the hazard area and will be discussed later. Also of note, due to the large potential hazard area, this posterior has a very strong correlation with Model Sensitivity (Figure \ref{fig_sensitivity}). The correlation is not a coincidence. These two metrics will always have a high linear agreement given a very large abundance of true negatives. This fact is explained in an Appendix following this report.

		\paragraph{Hazard Response Implications} The higher $P(\neg Lava|\neg Sim)$ is for a lava spreading algorithm, simulated safety (i.e. the similation does not predict inundation) at a given location more certainly predicts real safety at that location. This is the obverse of the previously discussed posterior metric, which relates simulated damage to actual damage. Algorithms known to have high $P(\neg Lava|\neg Sim)$ values should influence fewer people to evacuate an area that is predicted by those algorithms to be safe. If $P(\neg Lava|\neg Sim)$ is low however, it is more likely that necessary evacuations would not occur, resulting in greater loss of infrastructure or even life.

	\subsection{Incorporating Model Uncertainty with Monte Carlo}
		In this section I will explore how model uncertainty might be incorporated in model validation. Model uncertainty is a result of input parameter uncertainty, such as elevation error, and may be estimated using the Monte Carlo method for the MOLASSES code. Elevation uncertainty is added to the MOLASSES code and each model of 1,000 unique model runs is analyzed using the above statistics. The distribution of these results will first be discussed. Then different levels of simulated inundation probability will be compared to the Tolbachik flow extent.

		MOLASSES flow parameters for the Monte Carlo model are listed below. 
		\begin{center}
			\textbf{Monte Carlo MOLASSES Flow Parameters}\\
			\begin{tabular}{l l}
				\toprule
				Elevation Model & 75-m SRTM\\
				Elevation Uncertainty, $1\sigma$ & 3~m\\
				Residual Thickness & 7.8~m\\
				Pulse Volumes & 44200 m$^3$\\
				\midrule
				Vent$_N$ Easting & 582800~m (UTM Zone 57)\\
				Vent$_N$ Northing & 6182100~m\\
				Vent$_N$ Total Volume & 4.63$\cdot10^7$~m$^3$\\
				\midrule
				Vent$_S$ Easting & 582475~m\\
				Vent$_S$ Northing & 6180700~m\\
				Vent$_S$ Total Volume & 1.737$\cdot10^8$~m$^3$\\
				\bottomrule
			\end{tabular}
		\end{center}
		In this section SRTM data is used, with a spatial resolution of 75~m per pixel. Vertical uncertainty is estimated by \citet{rodriguez2006global} for Eurasia to be 6.2~m at a 90\% confidence level and is shown to be randomly distributed. Because of this, elevation uncertainty in the MOLASSES model is given a value of $1\sigma=3$~m. Each elevation value from the SRTM grid is initially assigned a value that deviates from the given elevation by a random amount with a gaussian standard deviation, $\sigma$, again set at 3~m. A lava flow is simulated over this surface. For the Monte Carlo process, this is repeated 1,000 times.

		\subsection{Model fit distribution of 1,000 simulations}
		The reliability of a model can be better understood by showing the distribution of model performance given model uncertainty, as opposed to treating model parameters and thus model output as completely certain. The metrics discussed above, specifically the posterior, the negative posterior, model sensitivity, and the Jaccard fit are calculated for each flow simulation based on the 2012-3 Tolbachik mapped flow. The distributions of each of these metrics is graphed in Figure \ref{fig:MC_dist}.

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{figures/MC_map}
\caption{Cumulative distribution of 1,000 simulated lava flows over SRTM topography with 3~m elevation uncertainty. The red outline is the mapped flow extent of the 2012-3 Tolbachik flow. The flow source vents are mapped as red triangles.}
\label{fig:MC_map}
\end{figure}

%Graph of the performances
\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{figures/bayes_graphs}
\caption{Distributions of fitness statistics between the 2012-3 Tolbachik Lava Flows and 1,000 simulated lava flows over SRTM topography with 3~m standard elevation uncertainty. Vertical lines are the fitness of a simulated lava flow run over SRTM data assuming 0~m elevation uncertainty. The better than average fit for this simulation might suggest that topography is locally known better than 3~m.}
\label{fig:MC_dist}
\end{figure}


\subsection{Model fit at different simulated inundation probabilities}
By creating a cumulative map of lava flow simulations in the Monte Carlo (Figure \ref{fig:MC_map}), $P(Sim)$ may be estimated for every location as opposed to for the entire hazard area.

\begin{figure}[h!]
	\centering
	\begin{gnuplot}[terminal=latex, terminaloptions=rotate]
		unset key
		set size 0.7,0.7
		set format xy "$%g$"
		set xlabel "Minimum $P(Sim)$" rotate by 90
		set ylabel "$P(Lava|Sim)$"
		set ytics 0.1
		set ytics nomirror
		set y2tics 0.005
		set y2label "$P($not $Lava|$not $Sim)$"
		plot "results_cum.dat" using 1:6 with linespoints lt 4 pt 7 axes x1y1, "results_cum.dat" using 1:7 with linespoints lt 4 pt 6 axes x1y2, 
	\end{gnuplot}
	\caption{Bayesian Posteriors calculated for subsets of the cumulative distribution of 1,000 simulated flows in a Monte Carlo model. Black circles are posterior, $P(Lava|Sim)$ values; hollow circles are negative posterior, $P(\neg Lava|\neg Sim)$ values. Subsets are defined by all locations which have been hit by a minimum percentage of simulated flows. For instance, the far right dots are the posteriors calculated for locations inundated by every simulated flow.}
	\label{fig:MC_cum}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{gnuplot}[terminal=latex, terminaloptions=rotate]
		unset key
		set size 0.65,1
		set format xy "$%g$"
		set xlabel "$P(Sim)$" rotate by 90
		set ylabel "$P(Lava|Sim)$"
		set ytics 0.2
		set xtics 0.2
		set yrange [0:1]
		plot "results_parsed.dat" using 1:6 with points pt 7,  "results_parsed.dat" using 1:1 with lines lt 1
	\end{gnuplot}
	\caption{$P(Lava)$ calculated for locations given locations' $P(Sim)$, estimated using 1,000 simulated flows. Areas hit by 100\% of simulations are 88\% likely to be actually inundated. Areas hit by 1-5\% of simulations are about 5\% likely to be actually inundated. $P(Sim)$ is correlated with $P(Lava)$, but $P(Lava|Sim)$ rolls off at about $P(Sim)=65$\%.}
	\label{fig:MC_split}
\end{figure}

I have selected different subsets of the cumulative distribution of lava flows to evaluate using both posterior statistics, based on how many simulations hit given locations. Subsets are defined as all locations where at least a given percentage of simulated flows hit (e.g. the set of locations hit by more than 60\% of simulations, the set of locations hit by all simulations). The model fit between these subsets and the Tolbachik Flows are charted in Figure \ref{fig:MC_cum}. Points in this figure represent the probability of lava flow inundation at locations within each of these subsets. For example, 88\% of locations hit by every simulation are mapped as inundated; 75\% of locations hit by at least half of all simulations were inundated by lava; and 44\% of locations hit by at least one simulation were inundated by lava. The negative posterior is also charted in the same way: locations within the hazard area that were never hit by simulations were 99.9\% likely to remain uninundated; locations hit by fewer than half of all simulations were 99.6\% likely to not be inundated by lava; while only 98.7\% of areas remained uninundated when only locations hit by 100\% of simulations were removed.

By using this Monte Carlo method to incorporate uncertainty for an advancing lava flow, each location is assigned a probability of inundation by simulations. As the simulation is not perfect, this probability is not the same as the probability of actual inundation by lava (which is the whole reason for this report, after all). If a location is found to have a 20\% chance of inundation among simulated flows, is this similar to the probability of actual inundation? In Figure \ref{fig:MC_split} the posterior $P(Flow|Sim)$ is calculated for all locations hit by given percentages of simulations. Areas hit by $<$5\% of simulated flows all have a roughly 5\% chance of being inundated by the real flow. A positive correlation between this posterior and probability of simulation does exist in this view. The correlation appears to roll off as $P(Sim)$ approaches 65\%, as the limit of the model is reached.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%DISCUSSION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion and Conclusion}\label{sec:discussion}
	\subsection{Benchmark Validation}
	A valid model can be determined by elimination. Spreading algorithms that are not slope-proportional spreading methods can be eliminated in the Level 1 test. Of the four remaining algorithms, only 8-connected transition functions succeed in Level 2. Luckily, both of these 8-connected, slope-proportional spreading funtions also perform best in replicating the Tolbachik flows over SRTM. However, they do not pass the 50\% fit test over TanDEM-X.
	
	One reason why most flows do worse over the TanDEM-X DEM could be due to the Pulse Volume used. While this pulse volume is convenient, as it is defined by parameters known \textit{a priori}, it might be essential to test a range of pulse parameters to refine this parameter and find the best possible fit of flows over TanDEM-X data. This is the sixth and final step of the validation guide given by \citet{bayarri2007framework}.
	
	Overall, in all tests 8-connected models outperfom 4-connected models. While equal sharing algorithms outperfom slope-proportional sharing on a flat slope, they fail on a rotating DEM and perform about the same on real topography. There does not seem to be an unambiguously better choice between using parent-child relationships or not. If future tests continue to show similar performance between models with and without parentage, other reasons can be used to choose a model, such as computer run-time. Currently, the perferred model is one that spreads in 8 directions without parentage rules that delivers lava in a slope-proportional fashion.
	
	The strength of the MOLASSES code is that new algorithms, such as those used in the SCIARA model, can be implemented relatively quickly and run through the Benchmarking tests, which are written in Python. Combinations of implementation strategies can also be created on the fly by adjusting the makefile of the MOLASSES code instead of the code itself.

	\subsection{Bayesian Applications}
		Validation of lava flow models is important as a method of increasing the value of models to forecast lava flow processes, thereby decreasing preventable loss. Preventable loss can either be loss of property due to lava or expenditure of resources on a lava flow that never comes. Because loss of property is necessarily more valuable than a loss of resources to protect that property (since, if the resources to protect the property were more valuable, it would not make sense to use those resources), the posterior probability $P(\neg Lava|\neg Sim)$ is more important that the posterior probability $P(Lava|Sim)$. However, because $P(\neg Lava|\neg Sim)$ is dependent on the population size (i.e. the potential hazard area), it is harder to quantify.

		\paragraph{Using Bayesian statistics to compare models}

		In the pulse volume exercise, both the posterior and the negative posterior metrics were calculated for a number of simulations with differing pulse volumes. One pulse volume, 14040~m$^3$ per loop, performed best using the posterior statistic (Figure \ref{fig_lavaGsim}) and another, 4387~m$^3$ per loop, performed best using the negative posterior (Figure \ref{fig_neglavaGsim}). An optimal pulse volume can be identified if these metrics are given weight and compared. Because it is likely more important to have fewer false negatives (where destruction is unexpected) than false positives (where evacuation occurs but is not eventually needed), one might weight the negative posterior more importantly than the other posterior.

		To score simulations by combining the posteriors, I have normalized both posteriors so the worst scoring flow has a value of 0 and the best has a score of 1. I then took a weighted average of the normalized posteriors assuming the negative posterior is 10, 5, 2, and 1 times as important as the other posterior. These are graphed on the right of Figure \ref{fig:jaccard_combined}. Luckily, regardless of the weighting, the same pulse volume is always ranked highest (4387~m$^3$ per loop).

		It is interesting to note that the Jaccard Fit for these simulations (plotted on the left side of Figure \ref{fig:jaccard_combined}) is similar in shape to the weighted scores. The Jaccard fit is most similar to the combined scores where the posterior and negative posterior are given equal weight. In this case the correlation between the combined scores and the Jaccard fits have an r$^2$ value of 0.98.

		%%%%NOTES%%%%
		%The Jaccard model appears to be related to both posterior functions
		%Changing Population size (Improvement in neg Post and Improvement in learning)
		%Weighted average


		\begin{figure}
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\begin{gnuplot}[terminal=latex, terminaloptions=rotate]
				unset key
				set size 0.6,0.7
				set format xy "$%g$"
				set xlabel "Pulse Volume" rotate by 90
				set ylabel "Jaccard Fit"
				set ytics 0.02
				set xtics 5000
				plot "results_bayes.dat" using 1:5 with linespoints lt 4 pt 7
			\end{gnuplot}
			\label{fig:sub1}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\begin{gnuplot}[terminal=latex, terminaloptions=rotate]
				unset key
				set size 0.6,0.7
				set format xy "$%g$"
				set xlabel "Pulse Volume" rotate by 90
				set ylabel "Combined Score"
				set ytics 0.1
				set xtics 5000
				plot "results_combinedpost.dat" using 1:7 with linespoints lt 4 pt 1, "results_combinedpost.dat" using 1:5 with linespoints lt 4 pt 7, "results_combinedpost.dat" using 1:6 with linespoints lt 4 pt 3, "results_combinedpost.dat" using 1:4 with linespoints lt 4 pt 6,
		
			\end{gnuplot}
			\label{fig:sub2}
		\end{subfigure}
		\caption{Left, Jaccard Fit for MOLASSES flows with differing Pulse Volumes. Right, model score based on weighted averages between the posterior metric and the negative posterior metric. Hollow circles, negative posterior is 10 times weight of posterior; solid circles, 5 times weight; asterisks, 2 times weight; plusses, equal weight between posteriors.}
		\label{fig:jaccard_combined}
		\end{figure}

		\subsubsection{Falsely improving value metrics}

			It is possible to game the value metrics (i.e. model sensitivity and both posteriors), making a model appear better than it actually is at replicating the true flow, though steps can be taken to avoid this. Model sensitivity can be increased by increasing true positives regardless of false positives. The posterior $P(Lava|Sim)$ can be increased by reducing false positives regardless of false negatives. The posterior $P(\neg Lava|\neg Sim)$ can be decreased by artificially reducing the potential hazard area or increased by artificially increasing this area. Examples are given below.

			\paragraph{Gaming examples}
			As a flow simulation increases in areal extent, its model sensitivity will not decrease as long as inundated locations remain inundated. Because of this, a large flow that covers the entire hazard area will have a perfect model sensitivity score as it correctly predicts destruction of lava everywhere where lava actually will result. This hypothetical model however has little to no value in actually forecasting lava flow inundation. Again, model sensitivity can be gamed by increasing true positives without concern for false positives. 

			The posterior $P(Lava|Sim)$ can also be increased at the expense of actual model value. If the lava simulation extent covers a very small area centered, perhaps, at the lava source vents, the lava simulation will be less likely to have false positives. By reducing false positives, closer to 100\% of the simulation will actually be inundated by lava, increasing $P(Lava|Sim)$.

			As the posterior $P(\neg Lava|\neg Sim)$ is dependent on the hazard area size, changing this size can make this value better or worse for a model. By increasing the potential hazard area, the ``safe''-simulated area agrees more with the true ``safe'' area, as the true negatives increase proportional to false negatives. However, the usefulness of the model with increased hazard area decreases simply because $P(Lava)$ also decreases dramatically. If a house, for instance, is 100~km away and uphill from an erupting volcanic vent, $P(\neg Lava|\neg Sim)$ at the house's address does not impact the belief of its owners as $P(\neg Lava)$ is already almost certain. Also, after a certain hazard area size, it appears that models can be accurately compared against each other independent of hazard area size.

			Decreasing hazard area size however can make the  $P(\neg Lava|\neg Sim)$ of certain models worse artificially. As the hazard area approaches the area of the union between the lava flow and the simulation, true negatives are removed from the population. As $P(\neg Lava|\neg Sim)$ relies on only true negatives and false negatives, false negatives gain a higher proportion in this situation. If the hazard area is defined as the model and flow union area, the only model negative locations will be false negatives, and $P(\neg Lava|\neg Sim)$ will be 0. A model with 1 false negative in this situation will be worse than a model with 0 false negatives and hundreds of false positives.

			\paragraph{Avoiding value metric gaming} Several steps can be taken to insure the above metrics are useful in analyzing the value of lava flow models. First and foremost, the flow simulation results should replicate reality in more ways than areal extent. Specifically, simulation volume and ultimate flow thickness should be similar to the actual lava flow or potential flow. Constraining and checking these two values post-simulation will constrain the simulated areal extent to be similar to the actual lava flow. This secures the validity of model sensitivity and the posterior $P(Lava|Sim)$. 

			Second, the hazard area should be defined based on geographic and geologic information, which essentially creates a more simple lava flow model (possibly ``Type II'' from \citet{harris2013lava}) that encompasses all possible lava-affected areas (i.e. it has a near 100\% model sensitivity and a low specificity on purpose). In Section \ref{sec_negpost} for instance, I follow Kilburn's maximum runout distance equation and assign the hazard area to be anywhere below the vent within the maximum distance in any direction. This however gives very high $P(\neg Lava|\neg Sim)$ values, $P(Lava)$ is small for the entire area, so a better hazard area might be defined some other way. One possibility is by identifying catchments that the lava flow could possibly enter \citep{kauahikaua1995applications} and using the maximum distance method on those smaller areas.
		
		\subsubsection{Bayesian Conclusions}
			Regardless of how a lava flow model is chosen, its value in forecasting lava flow hazards can be quantified using Bayesian statistics. Whether the model is bad or good, if it can be compared against a real life lava flow such as the 2012-3 Tolbachik flow, the two posteriors discussed in this paper can be calculated.

			By calculating $P(\neg Lava|\neg Sim)$, one may update their belief of safety based on a negative, or not-hit, result from the simulation. By calculating $P(Lava|Sim)$, one may update their belief of destruction by lava based on a positive hit result from the simulation. These two tools are potentially the most important metrics by which decision makers should base their faith in a given lava flow model.

			By comparing the posterior values of multiple lava flow algorithms, the best lava flow algorithm can be identified. The more important posterior metric is the $P(\neg Lava|\neg Sim)$, as a low value would indicate more false negatives, resulting in more unpredicted destruction. $P(Lava|Sim)$ is important but less so as low values indicate more false positives, which results in greater levels of unpredicted non-destruction. While these are a trade off, selecting the best model to decrease economic loss can be achieved by taking a weighted average of the two statistics. The weight given to each would depend on potential social or economic loss from evacuation or destruction of property. In this report, the best Pulse Volume was identified to be 4387~m$^3$ over TanDEM-X data in this area.

The two Bayesian posteriors are an improvement over model sensitivity and specificity as they provide a probability estimate that a simulated result is correct. By incorporating model uncertainty and performing a Monte Carlo for the MOLASSES lava flow algorithm, $P(Sim)$ can be estimated for each given location, improving the usefulness of Bayesian statistics in hazard analysis.
	
\section{Data Statement}
This code is available for free use on GitHub at the USFVolcanology page located at \url{https://github.com/USFvolcanology}, while the benchmarking codes can be found at \url{https://github.com/jarichardson/MOLASSES_benchmarking}. The MOLASSES code and the Benchmarking algorithms are kept in seperate self-contained repositories.

%\section{Acknowledgments}
%The development of this code was supported by SSI Grant

\bibliographystyle{plainnat}
\bibliography{molasses}

%\begin{figure}
%\centering
%\includegraphics[width=\linewidth]{map_diff}
%\label{fig:map_diff}
%\end{figure}


\end{document}
